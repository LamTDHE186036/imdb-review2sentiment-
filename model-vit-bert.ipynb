{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":103210,"databundleVersionId":12423451,"sourceType":"competition"},{"sourceId":12069801,"sourceType":"datasetVersion","datasetId":7597384}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:39:54.641864Z","iopub.execute_input":"2025-07-01T13:39:54.642141Z","iopub.status.idle":"2025-07-01T13:39:58.367042Z","shell.execute_reply.started":"2025-07-01T13:39:54.642112Z","shell.execute_reply":"2025-07-01T13:39:58.366257Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize # cắt câu thành từng từ (tokenize) bằng thư viện NLTK (Natural Language Toolkit).\nfrom nltk.corpus import stopwords       # danh sách các từ không có nhiều ý nghĩa (như “và”, “là”, “của”,...) để loại bỏ khi xử lý ngôn ngữ.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:40:03.124906Z","iopub.execute_input":"2025-07-01T13:40:03.125399Z","iopub.status.idle":"2025-07-01T13:40:04.075281Z","shell.execute_reply.started":"2025-07-01T13:40:03.125354Z","shell.execute_reply":"2025-07-01T13:40:04.074709Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Đường dẫn đến file CSV và folder ảnh\ncsv_path = '/kaggle/input/okok1230/dev_images_json_csv.csv'  \nimage_folder = '/kaggle/input/2025-sum-dpl-302-m/devset_images/devset_images'\ncsv_path_test = '/kaggle/input/2025-sum-dpl-302-m/test.csv'\nimage_folder_test = '/kaggle/input/2025-sum-dpl-302-m/testset_images/testset_images'\n\n# Đọc file CSV\ndf = pd.read_csv(csv_path)\ndf_test = pd.read_csv(csv_path_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:40:05.696041Z","iopub.execute_input":"2025-07-01T13:40:05.696832Z","iopub.status.idle":"2025-07-01T13:40:05.802168Z","shell.execute_reply.started":"2025-07-01T13:40:05.696807Z","shell.execute_reply":"2025-07-01T13:40:05.801580Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Xử lý dữ liệu văn bản: Gộp các cột title, description, user_tag\nimport re #Dùng để tìm kiếm, kiểm tra, và xử lý chuỗi văn bản theo mẫu (pattern)\n\ndef preprocess_text(text):\n    if pd.isna(text):  # Xử lý NaN\n        return \"\"\n    \n    text = str(text).lower() # Ép text thành chuỗi (trường hợp nó không phải chuỗi), sau đó chuyển toàn bộ thành chữ thường để chuẩn hóa.\n    text = re.sub(r'[^\\w\\s]', '', text)  # Xóa ký tự đặc biệt # [^\\w\\s] nghĩa là \"mọi ký tự không phải chữ, số, gạch dưới, hoặc khoảng trắng\"\n    tokens = word_tokenize(text) #word_tokenize từ thư viện NLTK để chia câu thành từng từ riêng biệt (token).\n    \n    stop_words = set(stopwords.words('english')) #Lấy tập các từ stopwords tiếng Anh\n    important_words = {'no', 'not', 'nor', 'never'} # Tạo tập từ quan trọng (đảo nghĩa) dù chúng là stopwords nhưng cần giữ lại để không làm mất nghĩa câu.\n    filtered_tokens = [t for t in tokens if (t not in stop_words or t in important_words)]\n    \n    return ' '.join(filtered_tokens) #Ghép các từ đã lọc thành chuỗi mới, cách nhau bằng dấu cách, rồi trả về kết quả.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:40:08.354071Z","iopub.execute_input":"2025-07-01T13:40:08.354727Z","iopub.status.idle":"2025-07-01T13:40:08.359801Z","shell.execute_reply.started":"2025-07-01T13:40:08.354686Z","shell.execute_reply":"2025-07-01T13:40:08.359213Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Tạo cột combined_text\ndf['combined_text'] = df['title'].apply(preprocess_text) + ' ' + \\\n                      df['description'].apply(preprocess_text) + ' ' + \\\n                      df['user_tag'].apply(preprocess_text)\n\ndf_test['combined_text'] = df_test['title'].apply(preprocess_text) + ' ' + \\\n                           df_test['description'].apply(preprocess_text) + ' ' + \\\n                           df_test['user_tags'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:40:08.699646Z","iopub.execute_input":"2025-07-01T13:40:08.700146Z","iopub.status.idle":"2025-07-01T13:40:12.470006Z","shell.execute_reply.started":"2025-07-01T13:40:08.700121Z","shell.execute_reply":"2025-07-01T13:40:12.469258Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from transformers import BertTokenizer #bộ tokenizer chuẩn để chuyển câu thành token cho mô hình BERT.\nimport torchvision.transforms as T \n\n# Load tokenizer BERT base uncased\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # Tạo đối tượng tokenizer cho BERT base uncased (không phân biệt hoa thường), \n                                                               # from_pretrained tải sẵn vocab và cấu hình của tokenizer từ thư viện Hugging Face.\n                                                               # Ví dụ: câu \"I love AI!\" có thể được tách thành các token: [\"I\", \"love\", \"AI\", \"!\"].\n\n\n# Image transform (ImageNet chuẩn)\nimage_transform = T.Compose([\n    T.Resize((224, 224)),\n    T.ToTensor(), # Chuyển ảnh từ dạng PIL Image hoặc numpy array sang tensor PyTorch.  pixel mới = pixel cũ / 255\n    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Mô hình CNN như ResNet, VGG... được huấn luyện với ảnh có phân phối màu sắc trung bình và độ lệch chuẩn như trên.\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:40:20.926453Z","iopub.execute_input":"2025-07-01T13:40:20.926721Z","iopub.status.idle":"2025-07-01T13:40:39.966616Z","shell.execute_reply.started":"2025-07-01T13:40:20.926699Z","shell.execute_reply":"2025-07-01T13:40:39.965691Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b4e967066644aa9584e2d99a8db42a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33204fc3dbd749afbf34c8bda4b31704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"796cfabeab6c449bb81037b590b9cfe7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d3bb37aa1094aefa41757f82486e5c9"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\n\ndef find_image_path(folder, image_id):\n    for ext in ['png', 'jpg', 'jpeg', 'gif']:\n        path = os.path.join(folder, f\"{image_id}.{ext}\")\n        if os.path.exists(path):\n            return path\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:40:47.143268Z","iopub.execute_input":"2025-07-01T13:40:47.144282Z","iopub.status.idle":"2025-07-01T13:40:47.150749Z","shell.execute_reply.started":"2025-07-01T13:40:47.144243Z","shell.execute_reply":"2025-07-01T13:40:47.149684Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class FloodDataset(Dataset):\n    def __init__(self, dataframe, image_folder, tokenizer, max_length=128, transform=None):\n        self.data = dataframe.reset_index(drop=True) #chứa thông tin ảnh và văn bản (image_id, combined_text, label)\n        self.image_folder = image_folder #thư mục chứa ảnh\n        self.tokenizer = tokenizer #BERT tokenizer để mã hóa văn bản\n        self.max_length = max_length \n        self.transform = transform if transform else transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406],\n                                 [0.229, 0.224, 0.225])\n        ])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx] #trả về một Series (tương tự một dòng) chứa thông tin của ảnh và văn bản tương ứng ở vị trí idx.\n        image_id = str(row['image_id']) #Lấy giá trị trong cột 'image_id' của dòng đó và chuyển thành kiểu chuỗi (string).\n        \n        image_path = find_image_path(self.image_folder, image_id) #Gọi hàm find_image_path để tìm đường dẫn file ảnh trong thư mục self.image_folder dựa vào image_id\n        if image_path is None:\n            print(f\"Image not found for id {image_id}\")\n            image = Image.new('RGB', (224, 224), (0, 0, 0)) # tạo ảnh đen\n        else:\n            image = Image.open(image_path).convert('RGB') # định dang sang RGB\n        \n        image = self.transform(image)\n        text = row['combined_text']\n        \n        encoded = self.tokenizer(\n            text,\n            max_length=self.max_length,\n            truncation=True, #nếu văn bản dài hơn max_length thì cắt bớt cho vừa\n            padding='max_length',# nếu văn bản ngắn hơn max_length thì thêm padding cho đủ độ dài.\n            return_tensors='pt' #trả về kết quả dưới dạng tensor PyTorch.\n        )\n        \n        label = torch.tensor(row['label'], dtype=torch.float) if 'label' in row else torch.tensor(0.0)\n        \n        return {\n            'image': image,\n            'input_ids': encoded['input_ids'].squeeze(0),\n            'attention_mask': encoded['attention_mask'].squeeze(0),\n            'label': label\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:40:48.651092Z","iopub.execute_input":"2025-07-01T13:40:48.651807Z","iopub.status.idle":"2025-07-01T13:40:48.659875Z","shell.execute_reply.started":"2025-07-01T13:40:48.651778Z","shell.execute_reply":"2025-07-01T13:40:48.659278Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\n\ntrain_dataset = FloodDataset(df, image_folder, tokenizer, transform=image_transform)\ntest_dataset = FloodDataset(df_test, image_folder_test, tokenizer, transform=image_transform)\ntrain_dataset, val_dataset = train_test_split(train_dataset, test_size=0.01)\n\ntrain_loader = DataLoader(train_dataset, batch_size=80, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=80, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=80, shuffle=False, num_workers=2)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:40:51.261911Z","iopub.execute_input":"2025-07-01T13:40:51.262222Z","iopub.status.idle":"2025-07-01T13:42:35.701539Z","shell.execute_reply.started":"2025-07-01T13:40:51.262196Z","shell.execute_reply":"2025-07-01T13:42:35.700818Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import BertModel, ViTModel\n\nclass FloodModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\") #Tải mô hình ViT đã được huấn luyện trước.\n        self.vit_fc = nn.Sequential(\n            nn.Linear(768, 256), ## Giảm chiều từ 768 → 256\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.3)\n        )\n\n        self.text_model = BertModel.from_pretrained(\"bert-base-uncased\") #Tải mô hình BERT đã được huấn luyện.\n        self.text_fc = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.3)\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 128),  # Ghép 256 (ảnh) + 256 (text) = 512 → 128\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.3),\n            nn.Linear(128, 1),\n            # nn.Sigmoid()  \n        )\n\n    def forward(self, image, input_ids, attention_mask):\n        img_feat = self.vit(pixel_values=image).last_hidden_state[:, 0, :] #[:, 0, :]: chỉ lấy CLS token (tức token tóm tắt toàn bộ ảnh) → shape (batch_size, 768)\n        img_feat = self.vit_fc(img_feat)\n\n        text_feat = self.text_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output #.pooler_output: đầu ra của token [CLS] (biểu diễn toàn câu) → shape (batch_size, 768)\n        text_feat = self.text_fc(text_feat)\n\n        combined = torch.cat((img_feat, text_feat), dim=1)\n        return self.classifier(combined) #ghép theo chiều đặc trưng → kết quả có shape (batch_size, 512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:43:01.701279Z","iopub.execute_input":"2025-07-01T13:43:01.701898Z","iopub.status.idle":"2025-07-01T13:43:21.736016Z","shell.execute_reply.started":"2025-07-01T13:43:01.701871Z","shell.execute_reply":"2025-07-01T13:43:21.735327Z"}},"outputs":[{"name":"stderr","text":"2025-07-01 13:43:05.121116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751377385.632260      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751377385.746628      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = FloodModel()\nmodel = nn.DataParallel(model)  # Chạy trên nhiều GPU\nmodel = model.to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:43:41.856158Z","iopub.execute_input":"2025-07-01T13:43:41.856792Z","iopub.status.idle":"2025-07-01T13:43:46.833751Z","shell.execute_reply.started":"2025-07-01T13:43:41.856767Z","shell.execute_reply":"2025-07-01T13:43:46.833121Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211e0e0b52f0419f8531304150c4a893"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5181004a809f43e1afb8b4d8aae43317"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2598a845bbfb41bfbb8023993acf20b9"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Vòng lặp huấn luyện và đánh giá\nfor epoch in range(5):\n    # Huấn luyện\n    model.train()\n    total_train_loss = 0\n    train_correct = 0\n    train_total = 0\n\n    for batch in train_loader:\n        images = batch['image'].to(device)\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device).float().unsqueeze(1)\n    \n        outputs = model.forward(images, input_ids, attention_mask)  \n        loss = criterion(outputs, labels)                      \n    \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n        total_train_loss += loss.item()\n        predictions = (outputs > 0.5).float()\n        train_correct += (predictions == labels).sum().item()\n        train_total += labels.size(0)\n    avg_train_loss = total_train_loss / len(train_loader)\n    train_accuracy = train_correct / train_total\n\n    # Đánh giá trên validation\n    model.eval()\n    total_val_loss = 0\n    val_correct = 0\n    val_total = 0\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            images = batch['image'].to(device)\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device).float().unsqueeze(1)\n    \n            outputs = model.forward(images, input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n    \n            total_val_loss += loss.item()\n            predictions = (outputs > 0.5).float()\n            val_correct += (predictions == labels).sum().item()\n            val_total += labels.size(0)\n\n    \n    avg_val_loss = total_val_loss / len(val_loader)\n    val_accuracy = val_correct / val_total\n\n    # In kết quả\n    print(f\"Epoch {epoch+1} -> Train Loss: {avg_train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} || \"\n          f\"Val Loss: {avg_val_loss:.4f} - Val Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:43:47.720816Z","iopub.execute_input":"2025-07-01T13:43:47.721494Z","iopub.status.idle":"2025-07-01T13:57:38.114940Z","shell.execute_reply.started":"2025-07-01T13:43:47.721467Z","shell.execute_reply":"2025-07-01T13:57:38.114029Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 -> Train Loss: 0.2761 - Train Accuracy: 0.9047 || Val Loss: 0.4353 - Val Accuracy: 0.8679\nEpoch 2 -> Train Loss: 0.1270 - Train Accuracy: 0.9644 || Val Loss: 0.5257 - Val Accuracy: 0.8491\nEpoch 3 -> Train Loss: 0.0736 - Train Accuracy: 0.9835 || Val Loss: 0.4019 - Val Accuracy: 0.8868\nEpoch 4 -> Train Loss: 0.0516 - Train Accuracy: 0.9901 || Val Loss: 0.4619 - Val Accuracy: 0.8868\nEpoch 5 -> Train Loss: 0.0330 - Train Accuracy: 0.9943 || Val Loss: 0.2931 - Val Accuracy: 0.9245\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\nmodel.eval() #Đây là một phương thức (method) của lớp mô hình trong PyTorch, dùng để chuyển mô hình sang chế độ đánh giá (evaluation mode).\npreds = []\nimage_ids = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch['image'].to(device)\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n\n        outputs = model.forward(images, input_ids, attention_mask)\n        preds_batch = (outputs > 0.5).long().cpu().numpy().squeeze() \n\n        preds.extend(preds_batch) #.extend() sẽ thêm từng phần tử của batch_ids vào image_ids\n \n        batch_ids = batch['image_id'] if 'image_id' in batch else None\n        if batch_ids is not None:\n            image_ids.extend(batch_ids)\n        else:\n            start_idx = len(image_ids)\n            end_idx = start_idx + len(preds_batch)\n            image_ids.extend(df_test['image_id'].iloc[start_idx:end_idx].tolist()) # chuyển thành list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:57:44.665194Z","iopub.execute_input":"2025-07-01T13:57:44.665988Z","iopub.status.idle":"2025-07-01T13:58:03.494150Z","shell.execute_reply.started":"2025-07-01T13:57:44.665959Z","shell.execute_reply":"2025-07-01T13:58:03.493258Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df_pred = pd.DataFrame({\n    'id': image_ids,\n    'label': preds\n})\n\ndf_pred.to_csv('test_predictions.csv', index=False)\nprint(\"Saved test predictions to test_predictions.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}